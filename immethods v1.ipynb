{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The usual fare\n",
    "# Importing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from astropy.io import fits\n",
    "import matplotlib.cm as cm\n",
    "import os \n",
    "import glob \n",
    "import astropy\n",
    "import scipy.signal\n",
    "from astropy.stats import sigma_clip\n",
    "import time\n",
    "from astropy import stats\n",
    "from PIL import Image\n",
    "import shift_methods as sm\n",
    "import textwrap as tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediancombine(filelist):\n",
    "    '''\n",
    "    Edit this docstring accordingly!\n",
    "    '''\n",
    "    n = len(filelist)\n",
    "    first_frame_data = fits.getdata(filelist[0])\n",
    "    imsize_y, imsize_x = first_frame_data.shape\n",
    "    fits_stack = np.zeros((imsize_y, imsize_x , n), dtype = np.float32) \n",
    "    for ii in range(0, n):\n",
    "        im = fits.getdata(filelist[ii])\n",
    "        fits_stack[:,:,ii] = im\n",
    "    med_frame = np.median(fits_stack, axis=2)\n",
    "    return med_frame\n",
    "# still need to median_bias = mediancombine(biasfiles)\n",
    "# fits.writeto('Backup_Master_Bias.fit', median_bias, biasheader, clobber=True)\n",
    "# Make Master Bias Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filesorter(filename, foldername, fitskeyword_to_check, keyword):\n",
    "    '''\n",
    "    This will sort your observation data files for you. It takes in the name of a file,\n",
    "    the folder you want it in, the keyword in fits to look for, and the keyword category\n",
    "    in fits to look for the keyword in. Ex. sorting calibrations into new folder --\n",
    "    filesorter(filename,'calibration','cal','OBJECT')\n",
    "    '''\n",
    "    if os.path.exists(filename):\n",
    "        pass\n",
    "    else:\n",
    "        print(filename + \" does not exist or has already been moved.\")\n",
    "        return\n",
    "    \n",
    "    header = fits.getheader(filename)\n",
    "    fits_type = header[keyword]\n",
    "    \n",
    "    if os.path.exists(foldername):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Making new directory: \" + foldername)\n",
    "        os.mkdir(foldername)\n",
    "        \n",
    "    if fits_type == fitskeyword_to_check:\n",
    "        destination = foldername + '/'\n",
    "        print(\"Moving \" + filename + \" to: ./\" + destination + filename)\n",
    "        os.rename(filename, destination + filename)  \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FileMover(filelist,foldername):\n",
    "        '''\n",
    "    do this docstring you asshole\n",
    "    '''\n",
    "        for file in filelist:\n",
    "            if os.path.exists(file):\n",
    "                pass\n",
    "            else:\n",
    "                print(file + \"does not exist or has already been moved\")\n",
    "                return\n",
    "            if os.path.exists(foldername):\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Making new directory:\" + foldername)\n",
    "                os.mkdir(foldername)\n",
    "            destination = foldername + '/'\n",
    "            print(\"Moving \" + file + \" to: ./\" + destination + file)\n",
    "            os.rename(file, destination + file)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomBias(filelist):\n",
    "    '''\n",
    "    do this docstring you asshole\n",
    "    '''\n",
    "    for file in filelist:\n",
    "        im = fits.getdata(file)\n",
    "        new_name = 'b_'+file[6:-7]+'.fits'\n",
    "        if im.shape == (4150,4150):\n",
    "            #im_name = file[6:-7]\n",
    "            overscan = np.mean(im[:,4100:4140])\n",
    "            custom_bias = overscan * mmaster_bias\n",
    "            bias_subtracted = im - custom_bias\n",
    "            bias_sub_overscan = bias_subtracted[:4110,:4090]\n",
    "            header = fits.getheader(filelist[0])\n",
    "            fits.writeto(new_name,bias_sub_overscan, header,overwrite=True)\n",
    "            print(new_name,'written.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masterflat(filelist,filt,flatdec,filtnum):\n",
    "    '''\n",
    "    do this docstring you asshole\n",
    "    '''\n",
    "    allimages=filelist\n",
    "    filt=filt\n",
    "    flat_images = []\n",
    "    for flat in allimages:\n",
    "        if fits.getheader(flat)['DECSTRNG']==flatdec and fits.getheader(flat)['FILTER2 ']==filtnum:\n",
    "            flat_images.append(flat)\n",
    "    print(flat_images)\n",
    "    try:\n",
    "        flat_header= fits.getheader(flat_images[0])\n",
    "        CustomBias(flat_images)\n",
    "        FileMover(flat_images,filt+'Flat')\n",
    "        b_flat_images = glob.glob('b_*.fits')\n",
    "        Master_Flat=norm_combine_flats(b_flat_images)\n",
    "        fits.writeto('Master'+filt+'Flat.fits',Master_Flat,flat_header,overwrite=True)\n",
    "        print('Master'+filt+'Flat Image Created')\n",
    "        FileMover(b_flat_images,filt+'_bflats')\n",
    "    except IndexError:\n",
    "        print(\"\"\"Couldn\\'t find any files. You might not have any data for this filter on this night. Check your logs.\"\"\")\n",
    "        \n",
    "    return Master_Flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatfield(filelist,masterflat):\n",
    "    '''\n",
    "    do this docstring you asshole\n",
    "    '''\n",
    "    filelist=filelist\n",
    "    masterflat = masterflat\n",
    "    print('Starting flatfielding')\n",
    "    print('*'*25)\n",
    "    for file in filelist:\n",
    "        data = fits.getdata(file)\n",
    "        header=fits.getheader(file)\n",
    "        flatfielded = data / masterflat\n",
    "        filename = 'f_'+file\n",
    "        fits.writeto(filename,flatfielded,header,overwrite=True)\n",
    "        print(file, 'has been flatfielded')\n",
    "        print('*'*25)\n",
    "    print('Done flatfielding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_combine_flats(filelist):\n",
    "    '''\n",
    "    This normalizes the flat field images. Each flat will have a \n",
    "    pixel value of ~1. Once we do this, we can then median combine\n",
    "    the flats to get our master flat for a given filter\n",
    "    '''\n",
    "    n = len(filelist)\n",
    "    first_frame_data = fits.getdata(filelist[0])\n",
    "    imsize_y, imsize_x = first_frame_data.shape\n",
    "    fits_stack = np.zeros((imsize_y, imsize_x , n), dtype = np.float32) \n",
    "    for ii in range(0, n):\n",
    "        im = fits.getdata(filelist[ii])\n",
    "        norm_im =  im/np.median(im)# finish new line here to normalize flats\n",
    "        fits_stack[:,:,ii] = norm_im\n",
    "    med_frame = np.median(fits_stack, axis=2)\n",
    "    return med_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageshifter(imlist):\n",
    "    '''\n",
    "    do this docstring you asshole\n",
    "    '''\n",
    "    imlist=imlist\n",
    "    imlist.sort()\n",
    "    # i=0\n",
    "    # worklist= imlist[i:i+3]\n",
    "    # for i in range(len(imlist)):\n",
    "    im1,hdr1 = fits.getdata(imlist[0],header=True)\n",
    "    #     # print(imlist[0])\n",
    "    xshifts={}\n",
    "    yshifts={}\n",
    "    shift_image={}\n",
    "\n",
    "    for index,filename in enumerate(imlist):\n",
    "        imstack = np.zeros([im1.shape[0],im1.shape[1],len(imlist)])\n",
    "        im = fits.getdata(filename)\n",
    "        xshifts[index],yshifts[index]=sm.cross_image(im1,im)\n",
    "        shift_image[index] = sm.shift_image(im,xshifts[index],yshifts[index])\n",
    "        name = 's_'+filename\n",
    "        fits.writeto(name,shift_image[index],hdr1,overwrite=True)\n",
    "        print(\"Shift for image\",name,\"is\",xshifts[index],yshifts[index])\n",
    "        print('FITS file written:',name)\n",
    "        print('*'*25)\n",
    "    print('Stacking done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ministack(imlist,obj,filt):\n",
    "    imlist=shifted\n",
    "    im1 = fits.getdata(shifted[0])\n",
    "    i=0\n",
    "    obj = obj\n",
    "    filt = filt\n",
    "    worklist=shifted[i:i+3]\n",
    "    print('Starting Ministacks')\n",
    "    print('*'*25)\n",
    "    for i in range(len(shifted)):\n",
    "        if worklist != []: \n",
    "            medianimage = mediancombine(worklist)\n",
    "            num = str(i)\n",
    "            header = fits.getheader(worklist[0])\n",
    "            fits.writeto(num+'_'+obj+'_'+filt+'_stack.fits',medianimage,header,overwrite=True)\n",
    "            print('Wrote FITS File:',num+'_'+obj+'_'+filt+'_stack.fits')\n",
    "            print('*'*25)\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        i+=i*i+3\n",
    "        worklist=imlist[i:i+3]\n",
    "    print('Done Ministacking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masterbias(directory,all_images):\n",
    "    for file in all_images:\n",
    "        filesorter(file,'bias',0.001,'EXPTIME')\n",
    "    biasdir = directory+'/bias'\n",
    "    os.chdir(biasdir)\n",
    "    print('Moving into',biasdir)\n",
    "    bias_images = glob.glob('*')\n",
    "    if bias_images ==[]:\n",
    "        print(tw.fill('No biases found. Check your logs. You might need to use the nearest night\\'s bias stack',50))\n",
    "        biasdir = input('Please type the file path to the nearest bias data')\n",
    "        os.chdir(biasdir)\n",
    "        new_ims=glob.glob('*.fits')\n",
    "        for file in new_ims:\n",
    "            filesorter(file,'bias',0.001,'EXPTIME')\n",
    "        os.chdir(biasdir+'/bias')\n",
    "        new_biases = glob.glob('*')\n",
    "        print(new_biases)\n",
    "        masterbias = mediancombine(new_biases)\n",
    "        biasheader = fits.getheader(new_biases[0])\n",
    "        \n",
    "    else: \n",
    "        masterbias = mediancombine(bias_images)\n",
    "        biasheader = fits.getheader(bias_images[0])\n",
    "    mmaster_bias = masterbias/np.median(masterbias)\n",
    "    fits.writeto('MasterBias.fits',mmaster_bias,biasheader,overwrite=True)\n",
    "    print('MasterBias.fits generated')\n",
    "    print('Master Bias array generated')\n",
    "    return mmaster_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scifinder(directory,obj,objdec,filtnum):\n",
    "    os.chdir(directory)\n",
    "    all_images = glob.glob('*.fits')\n",
    "    ims = []\n",
    "    for im in all_images:\n",
    "        if fits.getheader(im)['DECSTRNG']==objdec and fits.getheader(im)['FILTER2 ']==filtnum:\n",
    "            ims.append(im)\n",
    "    print('I found',len(ims),obj,'images in filter number',filtnum)\n",
    "    CustomBias(ims)\n",
    "    FileMover(ims,obj+'_'+filt+'_science')\n",
    "    ims_b = glob.glob('b_*.fits')\n",
    "    FileMover(ims_b,'b_'+obj+'_'+filt+'_science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(directory)\n",
    "all_images=glob.glob('*fits')\n",
    "mmaster_bias = masterbias(directory,all_images)\n",
    "os.chdir(directory)\n",
    "all_images=glob.glob('*fits')\n",
    "masterflat(all_images,filt,'+13:00:03','200')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "V410dec = '+28:24:51'\n",
    "HLTaudec= '+18:14:25'\n",
    "IC348dec='+32:03:34' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What directory of data do you want to work with? E:\\20190124\n",
      "Moving c8506t0398b00.fits to: ./bias/c8506t0398b00.fits\n",
      "Moving c8506t0399b00.fits to: ./bias/c8506t0399b00.fits\n",
      "Moving c8506t0400b00.fits to: ./bias/c8506t0400b00.fits\n",
      "Moving c8506t0401b00.fits to: ./bias/c8506t0401b00.fits\n",
      "Moving c8506t0402b00.fits to: ./bias/c8506t0402b00.fits\n",
      "Moving c8506t0403b00.fits to: ./bias/c8506t0403b00.fits\n",
      "Moving c8506t0404b00.fits to: ./bias/c8506t0404b00.fits\n",
      "Moving c8506t0405b00.fits to: ./bias/c8506t0405b00.fits\n",
      "Moving c8506t0406b00.fits to: ./bias/c8506t0406b00.fits\n",
      "Moving c8506t0407b00.fits to: ./bias/c8506t0407b00.fits\n",
      "Moving c8507t0040b00.fits to: ./bias/c8507t0040b00.fits\n",
      "Moving c8506t0397b00.fits to: ./bias/c8506t0397b00.fits\n",
      "Normalized Master Bias array generated\n",
      "Norm_Master_Bias.fits generated\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c8506t0398b00.fits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-bb0b274bc6fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Norm_Master_Bias.fits generated'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mbiasheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# gets fits header for bias frames\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mmaster_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmediancombine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_images\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# performs median combo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mmmaster_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaster_bias\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaster_bias\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# normalizes the master bias for overscan scaling later\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\astropy\\io\\fits\\convenience.py\u001b[0m in \u001b[0;36mgetheader\u001b[1;34m(filename, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_file_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[0mhdulist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextidx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_getext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mhdu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhdulist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mextidx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\astropy\\io\\fits\\convenience.py\u001b[0m in \u001b[0;36m_getext\u001b[1;34m(filename, mode, ext, extname, extver, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'extver alone cannot specify an extension.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1011\u001b[1;33m     \u001b[0mhdulist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitsopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhdulist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py\u001b[0m in \u001b[0;36mfitsopen\u001b[1;34m(name, mode, memmap, save_backup, cache, lazy_load_hdus, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     return HDUList.fromfile(name, mode, memmap, save_backup, cache,\n\u001b[1;32m--> 164\u001b[1;33m                             lazy_load_hdus, **kwargs)\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py\u001b[0m in \u001b[0;36mfromfile\u001b[1;34m(cls, fileobj, mode, memmap, save_backup, cache, lazy_load_hdus, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m         return cls._readfrom(fileobj=fileobj, mode=mode, memmap=memmap,\n\u001b[0;32m    399\u001b[0m                              \u001b[0msave_backup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_backup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m                              lazy_load_hdus=lazy_load_hdus, **kwargs)\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\astropy\\io\\fits\\hdu\\hdulist.py\u001b[0m in \u001b[0;36m_readfrom\u001b[1;34m(cls, fileobj, data, mode, memmap, save_backup, cache, lazy_load_hdus, **kwargs)\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_File\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m                 \u001b[1;31m# instantiate a FITS file object (ffo)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 987\u001b[1;33m                 \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_File\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    988\u001b[0m             \u001b[1;31m# The Astropy mode is determined by the _File initializer if the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m             \u001b[1;31m# supplied mode was None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\astropy\\utils\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                         \u001b[1;31m# one with the name of the new argument to the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\astropy\\io\\fits\\file.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fileobj, mode, memmap, overwrite, cache)\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_fileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_filelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\astropy\\io\\fits\\file.py\u001b[0m in \u001b[0;36m_open_filename\u001b[1;34m(self, filename, mode, overwrite)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_read_compressed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfileobj_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIO_FITS_MODES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_on_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\astropy\\io\\fits\\util.py\u001b[0m in \u001b[0;36mfileobj_open\u001b[1;34m(filename, mode)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \"\"\"\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c8506t0398b00.fits'"
     ]
    }
   ],
   "source": [
    "obj = 'HL Tau'\n",
    "filt= 'Ha'\n",
    "# Master Bias Array and FITS file generation\n",
    "directory = input('Where can I find your bias files? ')\n",
    "os.chdir(directory)\n",
    "all_images=glob.glob('*.fits')\n",
    "for file in all_images:\n",
    "    filesorter(file,'bias',0.001,'EXPTIME') # get the biases\n",
    "os.chdir(directory+'/bias')\n",
    "bias_images=glob.glob('*') # gather bias images  \n",
    "try:\n",
    "    first_bias_data = fits.getdata(bias_images[0]) #\n",
    "    n = len(bias_images) # finds how man bias frames there are so \n",
    "                             # we can make the right sized array for them\n",
    "                             # to stack\n",
    "    imsize_y, imsize_x = first_bias_data.shape\n",
    "                             # gets the size of the image to make the\n",
    "                             # right sized array for all the pixel values\n",
    "    biasarray = np.zeros((imsize_y, imsize_x , n), dtype = np.float32)\n",
    "                         # make an empty array for all our stuff\n",
    "\n",
    "    for ii in range(0, n):\n",
    "        im = fits.getdata(bias_images[ii]) # gets the image data...\n",
    "        biasarray[:,:,ii] = im # and adds it to a layer of the array\n",
    "\n",
    "\n",
    "    biasheader = fits.getheader(bias_images[0]) # gets fits header for bias frames\n",
    "    master_bias = mediancombine(bias_images) # performs median combo\n",
    "    mmaster_bias = master_bias/np.mean(master_bias) # normalizes the master bias for overscan scaling later\n",
    "    print('Normalized Master Bias array generated')\n",
    "    fits.writeto('Norm_Master_Bias.fits',mmaster_bias,biasheader,overwrite=True)\n",
    "    print('Norm_Master_Bias.fits generated')\n",
    "    os.chdir(directory) \n",
    "except IndexError:\n",
    "    print('No biases found here.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where can I find your dome flats?E:\\20190122\\HaFlat\n",
      "['c8504t0163f00.fits', 'c8504t0164f00.fits', 'c8504t0165f00.fits', 'c8504t0166f00.fits', 'c8504t0167f00.fits']\n",
      "b_0163f.fits written.\n",
      "b_0164f.fits written.\n",
      "b_0165f.fits written.\n",
      "b_0166f.fits written.\n",
      "b_0167f.fits written.\n",
      "Making new directory:HaFlat\n",
      "Moving c8504t0163f00.fits to: ./HaFlat/c8504t0163f00.fits\n",
      "Moving c8504t0164f00.fits to: ./HaFlat/c8504t0164f00.fits\n",
      "Moving c8504t0165f00.fits to: ./HaFlat/c8504t0165f00.fits\n",
      "Moving c8504t0166f00.fits to: ./HaFlat/c8504t0166f00.fits\n",
      "Moving c8504t0167f00.fits to: ./HaFlat/c8504t0167f00.fits\n",
      "MasterHaFlat Image Created\n",
      "Making new directory:Ha_bflats\n",
      "Moving b_0163f.fits to: ./Ha_bflats/b_0163f.fits\n",
      "Moving b_0164f.fits to: ./Ha_bflats/b_0164f.fits\n",
      "Moving b_0165f.fits to: ./Ha_bflats/b_0165f.fits\n",
      "Moving b_0166f.fits to: ./Ha_bflats/b_0166f.fits\n",
      "Moving b_0167f.fits to: ./Ha_bflats/b_0167f.fits\n"
     ]
    }
   ],
   "source": [
    "# Master Flat generator\n",
    "directory = input('Where can I find your dome flats?')\n",
    "os.chdir(directory)\n",
    "all_images = glob.glob('c*.fits')\n",
    "MasterFlat = masterflat(all_images,'Ha','+13:00:03','200')\n",
    "#all_images = glob.glob('*.fits')\n",
    "os.chdir(directory)\n",
    "print('Moving back to '+directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where can I find some science images?E:\\20190112\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scifinder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5db51a12e28e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Where can I find some science images?'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# os.chdir(directory)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscifinder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'HLTau'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mHLTaudec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'200'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# biassub = glob.glob('b_*')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# flatfield(biassub,MasterFlat)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scifinder' is not defined"
     ]
    }
   ],
   "source": [
    "directory = input('Where can I find some science images?')\n",
    "# os.chdir(directory)\n",
    "scifinder(directory,'HLTau',HLTaudec,'200')\n",
    "# biassub = glob.glob('b_*')\n",
    "# flatfield(biassub,MasterFlat)\n",
    "# flatfielded = glob.glob('f_b_*')\n",
    "# imageshifter(flatfielded)\n",
    "# all_images=glob.glob('*.fits')\n",
    "# all_images\n",
    "# ims = []\n",
    "# for im in all_images:\n",
    "#     if fits.getheader(im)['DECSTRNG']==HLTaudec and fits.getheader(im)['FILTER2 ']=='200':\n",
    "#         ims.append(im)\n",
    "#         print(ims)\n",
    "# os.chdir(directory)\n",
    "\n",
    "# filtnum = '200'\n",
    "# objdec = HLTaudec\n",
    "# obj = 'HL Tau'\n",
    "# all_images = glob.glob('*.fits')\n",
    "# ims = []\n",
    "# for im in ims:\n",
    "#     if fits.getheader(im)['DECSTRNG']==objdec and fits.getheader(im)['FILTER2 ']==filtnum:\n",
    "#         ims.append(im)\n",
    "# print('I found',len(ims),obj,'images in filter number',filtnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting flatfielding\n",
      "*************************\n",
      "b_0110o.fits has been flatfielded\n",
      "*************************\n",
      "b_0112o.fits has been flatfielded\n",
      "*************************\n",
      "b_0111o.fits has been flatfielded\n",
      "*************************\n",
      "Done flatfielding\n"
     ]
    }
   ],
   "source": [
    "os.chdir(directory+'/b_'+obj+'_'+filt+'_science')\n",
    "b_sciims=glob.glob('b_*')\n",
    "flatfield(b_sciims,MasterFlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shift for image s_f_b_0110o.fits is 0.0 0.0\n",
      "FITS file written: s_f_b_0110o.fits\n",
      "*************************\n",
      "Shift for image s_f_b_0111o.fits is 0.2816938290275175 1.1856918281289381\n",
      "FITS file written: s_f_b_0111o.fits\n",
      "*************************\n",
      "Shift for image s_f_b_0112o.fits is -0.0991369429475526 -0.04191010767704029\n",
      "FITS file written: s_f_b_0112o.fits\n",
      "*************************\n",
      "Stacking done!\n",
      "Starting Ministacks\n",
      "*************************\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-5cff81e521c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimageshifter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflatfielded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mshifted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m's_*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mministack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshifted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'HLTau'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Ha'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-3c2fa51457bb>\u001b[0m in \u001b[0;36mministack\u001b[1;34m(imlist, obj, filt)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mworklist\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mmedianimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmediancombine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworklist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mfits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_stack.fits'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmedianimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Wrote FITS File:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_stack.fits'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num' is not defined"
     ]
    }
   ],
   "source": [
    "directory = 'E:/20190122/b_HL Tau_Ha_science'\n",
    "os.chdir(directory)\n",
    "flatfielded = glob.glob('f_b_*')\n",
    "imageshifter(flatfielded)\n",
    "shifted = glob.glob('s_*')\n",
    "ministack(shifted,'HLTau','Ha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Ministacks\n",
      "*************************\n",
      "Wrote FITS File: 0_HLTau_Ha_stack.fits\n",
      "*************************\n",
      "Done Ministacking\n"
     ]
    }
   ],
   "source": [
    "shifted = glob.glob('s_*')\n",
    "header=fits.getheader(shifted[0])\n",
    "ministack(shifted,'HLTau','Ha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ministack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd 20190113/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images=glob.glob('*.fits')\n",
    "for file in all_images:\n",
    "    filesorter(file,'bias',0.001,'EXPTIME') # get the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd bias/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images=glob.glob('*.fits')\n",
    "for file in all_images:\n",
    "    filesorter(file,'bias',0.001,'EXPTIME') # get the biases\n",
    "os.chdir('\\bias\\')\n",
    "bias_images=glob.glob('*') # gather bias images\n",
    "first_bias_data = fits.getdata(bias_images[0]) #\n",
    "n = len(bias_images) # finds how man bias frames there are so \n",
    "                     # we can make the right sized array for them\n",
    "                     # to stack\n",
    "imsize_y, imsize_x = first_bias_data.shape\n",
    "                     # gets the size of the image to make the\n",
    "                     # right sized array for all the pixel values\n",
    "biasarray = np.zeros((imsize_y, imsize_x , n), dtype = np.float32)\n",
    "                     # make an empty array for all our stuff\n",
    "    \n",
    "for ii in range(0, n):\n",
    "    im = fits.getdata(bias_images[ii]) # gets the image data...\n",
    "    biasarray[:,:,ii] = im # and adds it to a layer of the array\n",
    "    \n",
    "\n",
    "biasheader = fits.getheader(bias_images[0]) # gets fits header for bias frames\n",
    "master_bias = mediancombine(bias_images) # performs median combo\n",
    "mmaster_bias = master_bias/np.mean(master_bias) # normalizes the master bias for overscan scaling later\n",
    "print('Normalized Master Bias array generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('E:/20190113')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imlist=glob.glob('*.fits')\n",
    "masterflat(imlist,'Ha','+13:00:03','200')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('E:/20190112')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_haflat = fits.getdata(os.getcwd()+\"\\MasterHaFlat.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allims=glob.glob('*.fits')\n",
    "allims.sort()\n",
    "allims\n",
    "\n",
    "masterflat(allims,'Ha','+13:00:03','200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
